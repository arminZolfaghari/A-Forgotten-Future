{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9z96I6v2IKbi54JjU/x3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arminZolfaghari/A-Forgotten-Future/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "OvOIeMakjmqo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D2Ezl5DuNOLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "el0I04zjD_hc"
      },
      "outputs": [],
      "source": [
        "def generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(4096, activation=tf.nn.relu, input_shape=(9919,)))\n",
        "  model.add(layers.Dense(4096, activation=tf.nn.relu))\n",
        "  model.add(layers.Dense(4096, activation=tf.nn.relu))\n",
        "\n",
        "  model.add(layers.Reshape((4,4,256)))\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "  model.add(layers.Conv2DTranspose(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "  model.add(layers.Conv2DTranspose(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "  model.add(layers.Conv2DTranspose(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "  model.add(layers.Conv2DTranspose(filters=32, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "  model.add(layers.Conv2DTranspose(filters=3, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=tf.nn.relu))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32, (7,7), strides=(4,4), padding='valid', activation=tf.nn.relu, \n",
        "                          kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=0.1),\n",
        "                          bias_initializer=tf.zeros_initializer(),\n",
        "                          input_shape=[256, 256, 3]))\n",
        "  \n",
        "  model.add(layers.Conv2D(64, (5,5), strides=(1,1), padding='valid', activation=tf.nn.relu, \n",
        "                          kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "  \n",
        "  model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='valid', activation=tf.nn.relu, \n",
        "                          kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "  \n",
        "  model.add(layers.Conv2D(256, (3,3), strides=(1,1), padding='valid', activation=tf.nn.relu, \n",
        "                          kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "  \n",
        "  model.add(layers.Conv2D(256, (3,3), strides=(2,2), padding='valid', activation=tf.nn.relu, \n",
        "                          kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "  \n",
        "  model.add(layers.AveragePooling2D(pool_size=(11,11), strides=(11,11), padding=\"valid\"))\n",
        "\n",
        "  model.add(layers.Reshape((64, 256)))\n",
        "\n",
        "  model.add(layers.Dropout(rate=0.5))\n",
        "\n",
        "  model.add(layers.Dense(256, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=0.1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "\n",
        "  model.add(layers.Dropout(rate=0.5))\n",
        "\n",
        "  model.add(layers.Dense(2, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(factor=0.1),\n",
        "                          bias_initializer=tf.zeros_initializer()))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "szdIB0eUjeOJ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}